{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69d8c7c-0c21-424a-8ab5-e2d7ebdd3b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb66d7226cc34147bdb4fedcf639ee48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=True, description='LCZ'), Checkbox(value=True, description='SM'), Checkbox(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9ceb62f36048a19e13b24531eab6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Use normalized predictors?', options=('YES', 'NO'), style=DescriptionStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import Affine\n",
    "from shapely.geometry import Point\n",
    "from rasterstats import point_query\n",
    "#import xgboost as xgb\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "import math\n",
    "#from boruta import BorutaPy\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Predictor selection\n",
    "predictors_options = ['LCZ', 'SM', 'NDVI', 'NDLI', 'IMD', 'SWIR1', 'SWIR2', 'SVF', 'DTM', 'CH']\n",
    "checkboxes = [widgets.Checkbox(value=True, description=option) for option in predictors_options]\n",
    "checkbox_widget = widgets.VBox(checkboxes)\n",
    "display(checkbox_widget)\n",
    "\n",
    "# Normalization selection\n",
    "normalization_w = widgets.RadioButtons(\n",
    "    options=['YES', 'NO'],\n",
    "    description='Use normalized predictors?',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "display(normalization_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba775c55-a785-45be-a6e5-4aa9d2ad9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract once\n",
    "selected_predictors = [cb.description for cb in checkboxes if cb.value]\n",
    "normalization = normalization_w.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b8057-096a-42f3-a956-4ad5e595b353",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85dca5-bf9e-4afa-86a9-876770283383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_pipeline(month, hour, predictors, normalization):\n",
    "\n",
    "    print(f\"Running pipeline for {month} - {hour}...\")\n",
    "\n",
    "    # Load temperature data\n",
    "    #data = f'../Data/CML/HW_extracted/HW_{month}_2022/CML-ARPA_HW_{month}_2022_{hour}.csv'\n",
    "    data = f'../Data/CML/HW_extracted/alt_corr/CML-ARPA_HW_{month}_2022_{hour}.csv'\n",
    "    data_df = pd.read_csv(data)\n",
    "\n",
    "    geometry = [Point(xy) for xy in zip(data_df['long'], data_df['lat'])]\n",
    "    data_gdf = gpd.GeoDataFrame(data_df, geometry=geometry, crs='EPSG:4326')\n",
    "    data_gdf = data_gdf.to_crs(epsg=32632)\n",
    "\n",
    "    # Merge LCZ and train/test labels\n",
    "    data_class_df = pd.read_csv('../Data/LCZ/ARPA_CML_stations_LCZ.csv', delimiter=',')\n",
    "    data_class_df = data_class_df[['station', 'dominant_class', 'train/test']]\n",
    "    data_class_df.rename(columns={'dominant_class': 'LCZ'}, inplace=True)\n",
    "\n",
    "    merged_df = pd.merge(data_gdf, data_class_df, on='station', how='inner')\n",
    "    data_train = merged_df.loc[merged_df['train/test'] == 'train'].copy()\n",
    "    data_test = merged_df.loc[merged_df['train/test'] == 'test'].copy()\n",
    "\n",
    "    # Select predictor paths\n",
    "    predictors_dict = {\n",
    "        'NDVI': f'../Data/NDVI/NDVI_2022_{month}_mean.tif',\n",
    "        'LCZ': f'../Data/LCZ/LCZ_{month}_20m_majority.tif',\n",
    "        'IMD': '../Data/IMD_Copernicus_2018/IMD_Copernicus_2018_20m_mean.tif',\n",
    "        'SWIR1': f'../Data/SWIR/SWIR1_2022_{month}_mean.tif',\n",
    "        'SWIR2': f'../Data/SWIR/SWIR2_2022_{month}_mean.tif',\n",
    "        'SVF': '../Data/SVF/SVF_Final_20m_mean.tif',\n",
    "        'DTM': '../Data/Elevation/Elevation_20m_mean.tif',\n",
    "        'SM': f'../Data/Soil_Moisture/Soil_Moisture_2022_{month}_mean.tif',\n",
    "        'CH': '../Data/Canopy_Heights_ETH/Canopy_Heights_ETH_20m_norm_mean.tif'\n",
    "    }\n",
    "\n",
    "    if normalization == 'YES':\n",
    "        predictors_dict.update({\n",
    "            'LCZ': f'../Data/LCZ/LCZ_{month}_20m_norm_majority.tif',\n",
    "            'IMD': '../Data/IMD_Copernicus_2018/IMD_Copernicus_2018_20m_norm_mean.tif',\n",
    "            'SWIR1': f'../Data/SWIR/SWIR1_2022_{month}_norm_mean.tif',\n",
    "            'SWIR2': f'../Data/SWIR/SWIR2_2022_{month}_norm_mean.tif',\n",
    "            'DTM': '../Data/Elevation/Elevation_20m_norm_mean.tif',\n",
    "        })\n",
    "\n",
    "    predictors_dict = {k: v for k, v in predictors_dict.items() if k in predictors}\n",
    "    \n",
    "    # Sample predictors\n",
    "    for pred in predictors_dict:\n",
    "        raster = predictors_dict[pred]\n",
    "        data_train[pred] = point_query(data_train.geometry, raster, nodata=-999)\n",
    "        data_test[pred] = point_query(data_test.geometry, raster, nodata=-999)\n",
    "\n",
    "    # Train/Test split\n",
    "    X_train = data_train[predictors]\n",
    "    y_train = data_train['avg_temp']\n",
    "    X_test = data_test[predictors]\n",
    "    y_test = data_test['avg_temp']\n",
    "\n",
    "    # Train model (Here uncomment in the case of defined HP or default HP)\n",
    "    # regr = ensemble.RandomForestRegressor(\n",
    "    # n_estimators=200,\n",
    "    # max_depth=10,         # limit tree depth\n",
    "    # min_samples_leaf=5,   # reduce variance\n",
    "    # max_features='sqrt',  # prevent over-reliance on a few features\n",
    "    # random_state=42\n",
    "    # )\n",
    "    # For default HP\n",
    "    regr = ensemble.RandomForestRegressor(random_state=42)\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = regr.predict(X_test)\n",
    "    mae = round(mean_absolute_error(y_test, y_pred), 3)\n",
    "    rmse = round(math.sqrt(mean_squared_error(y_test, y_pred)), 3)\n",
    "    r2_test = round(r2_score(y_test, y_pred), 3)\n",
    "\n",
    "    # NEW: Predict on train set\n",
    "    y_train_pred = regr.predict(X_train)\n",
    "    mae_train = round(mean_absolute_error(y_train, y_train_pred), 3)\n",
    "    rmse_train = round(math.sqrt(mean_squared_error(y_train, y_train_pred)), 3)\n",
    "    r2_train = round(r2_score(y_train, y_train_pred), 3)\n",
    "\n",
    "    # Feature importance\n",
    "    feat_imp = dict(zip(predictors, regr.feature_importances_))\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Done → TEST → MAE: {mae}, RMSE: {rmse}, R2: {r2_test}\")\n",
    "    print(f\"         TRAIN → MAE: {mae_train}, RMSE: {rmse_train}, R2: {r2_train}\")\n",
    "\n",
    "    raster_arrays = []\n",
    "    for pred in predictors:\n",
    "        with rasterio.open(predictors_dict[pred]) as src:\n",
    "            array = src.read(1).astype(np.float32)\n",
    "            raster_arrays.append(array)\n",
    "            if pred == predictors[0]:  # Use first raster for metadata\n",
    "                meta = src.meta.copy()\n",
    "\n",
    "    stack = np.stack(raster_arrays, axis=0)  # shape: (num_bands, height, width)\n",
    "    n_bands, height, width = stack.shape\n",
    "    flat_stack = stack.reshape(n_bands, -1).T  # shape: (pixels, bands)\n",
    "\n",
    "    # Predict on full raster\n",
    "    pred_full = regr.predict(flat_stack)\n",
    "    pred_raster = pred_full.reshape(height, width)\n",
    "\n",
    "    # Save prediction to GeoTIFF\n",
    "    meta.update({\n",
    "        'count': 1,\n",
    "        'dtype': 'float32'\n",
    "    })\n",
    "    #out_path = f'../Data/Predicted_maps/Automated/no_SM/no_FS_defined_HP/red_rf_{month}_{hour}.tif'\n",
    "    out_path = f'../Data/Predicted_maps/Automated/alt_corr/no_SM/no_FS_default_HP/pred_rf_{month}_{hour}.tif'\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with rasterio.open(out_path, 'w', **meta) as dst:\n",
    "        dst.write(pred_raster.astype(np.float32), 1)\n",
    "\n",
    "    print(f\"Prediction raster saved to {out_path}\")\n",
    "    \n",
    "    # Save results\n",
    "    result = {\n",
    "        'month': month,\n",
    "        'hour': hour,\n",
    "        'MAE_test': mae,\n",
    "        'RMSE_test': rmse,\n",
    "        'R2_test': r2_test,\n",
    "        'MAE_train': mae_train,\n",
    "        'RMSE_train': rmse_train,\n",
    "        'R2_train': r2_train,\n",
    "        **feat_imp  # this unpacks the feature importances\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd7225-7bb8-4d65-893a-faad0d660a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = []\n",
    "months = ['Feb', 'May', 'June', 'July', 'Oct']\n",
    "hours = ['HP', 'WP', 'CP1', 'CP2', 'MUHI']\n",
    "\n",
    "for m in months:\n",
    "    for h in hours:\n",
    "        result = run_rf_pipeline(m, h, selected_predictors, normalization)\n",
    "        results_all.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c59df-fbf4-4d94-9c81-5a43f0b89acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to DataFrame\n",
    "results_df = pd.DataFrame(results_all)\n",
    "results_df.to_csv('../Data/Predicted_maps/Automated/alt_corr/no_DTM/no_FS_default_HP/RF_results.csv', index=False)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d525f3f2-7976-4ec6-be1a-8d8a0470dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968db9c-eb50-4561-aa0e-facd9fdf452f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test with feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b8c56-d21f-4d34-bfe9-cc14e9622b15",
   "metadata": {},
   "source": [
    "**Here we also try split of 50/50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc2f9b-b8a6-42ed-aef4-0ee3b0ad860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_pipeline(month, hour, predictors, normalization):\n",
    "\n",
    "    print(f\"Running pipeline for {month} - {hour}...\")\n",
    "\n",
    "    # Load temperature data. Here uncomment when needed\n",
    "    #data = f'../Data/CML/HW_extracted/HW_{month}_2022/CML-ARPA_HW_{month}_2022_{hour}.csv'\n",
    "    data = f'../Data/CML/HW_extracted/alt_corr/CML-ARPA_HW_{month}_2022_{hour}.csv'\n",
    "    #data = f'../Data/CML/HW_extracted/meteotracker/22052022.csv'\n",
    "    data_df = pd.read_csv(data)\n",
    "\n",
    "    geometry = [Point(xy) for xy in zip(data_df['long'], data_df['lat'])]\n",
    "    data_gdf = gpd.GeoDataFrame(data_df, geometry=geometry, crs='EPSG:4326')\n",
    "    data_gdf = data_gdf.to_crs(epsg=32632)\n",
    "\n",
    "    # Merge LCZ and train/test labels\n",
    "    data_class_df = pd.read_csv('../Data/LCZ/ARPA_CML_stations_LCZ.csv', delimiter=',')\n",
    "    data_class_df = data_class_df[['station', 'dominant_class', 'train/test']]\n",
    "    data_class_df.rename(columns={'dominant_class': 'LCZ'}, inplace=True)\n",
    "\n",
    "    merged_df = pd.merge(data_gdf, data_class_df, on='station', how='inner')\n",
    "    data_train = merged_df.loc[merged_df['train/test'] == 'train'].copy()\n",
    "    data_test = merged_df.loc[merged_df['train/test'] == 'test'].copy()\n",
    "    # HERE WE ADD PART WITH 50/50 SPLIT\n",
    "    # data_train, data_test = train_test_split(\n",
    "    #     merged_df,\n",
    "    #     test_size=0.5,\n",
    "    #     random_state=42\n",
    "    # )\n",
    "\n",
    "    # Select predictor paths\n",
    "    predictors_dict = {\n",
    "        'NDVI': f'../Data/NDVI/NDVI_2022_{month}_mean.tif',\n",
    "        'LCZ': f'../Data/LCZ/LCZ_{month}_20m_majority.tif',\n",
    "        'IMD': '../Data/IMD_Copernicus_2018/IMD_Copernicus_2018_20m_mean.tif',\n",
    "        'SWIR1': f'../Data/SWIR/SWIR1_2022_{month}_mean.tif',\n",
    "        'SWIR2': f'../Data/SWIR/SWIR2_2022_{month}_mean.tif',\n",
    "        'SVF': '../Data/SVF/SVF_Final_20m_mean.tif',\n",
    "        'DTM': '../Data/Elevation/Elevation_20m_mean.tif',\n",
    "        'SM': f'../Data/Soil_Moisture/Soil_Moisture_2022_{month}_mean.tif',\n",
    "        'CH': '../Data/Canopy_Heights_ETH/Canopy_Heights_ETH_20m_norm_mean.tif'\n",
    "    }\n",
    "\n",
    "    if normalization == 'YES':\n",
    "        predictors_dict.update({\n",
    "            'LCZ': f'../Data/LCZ/LCZ_{month}_20m_norm_majority.tif',\n",
    "            'IMD': '../Data/IMD_Copernicus_2018/IMD_Copernicus_2018_20m_norm_mean.tif',\n",
    "            'SWIR1': f'../Data/SWIR/SWIR1_2022_{month}_norm_mean.tif',\n",
    "            'SWIR2': f'../Data/SWIR/SWIR2_2022_{month}_norm_mean.tif',\n",
    "            'DTM': '../Data/Elevation/Elevation_20m_norm_mean.tif',\n",
    "        })\n",
    "\n",
    "    predictors_dict = {k: v for k, v in predictors_dict.items() if k in predictors}\n",
    "\n",
    "    # Sample predictors\n",
    "    for pred in predictors_dict:\n",
    "        raster = predictors_dict[pred]\n",
    "        data_train[pred] = point_query(data_train.geometry, raster, nodata=-999)\n",
    "        data_test[pred] = point_query(data_test.geometry, raster, nodata=-999)\n",
    "\n",
    "    # Drop rows with any NaNs in predictors\n",
    "    data_train = data_train.dropna(subset=predictors)\n",
    "    data_test = data_test.dropna(subset=predictors)\n",
    "\n",
    "    # Use all predictors initially\n",
    "    X_train_full = data_train[predictors]\n",
    "    y_train = data_train['avg_temp']\n",
    "    X_test_full = data_test[predictors]\n",
    "    y_test = data_test['avg_temp']\n",
    "\n",
    "    # First train to get feature importances (Here uncomment in the case of defined predictors or default predictors)\n",
    "    # regr_full = ensemble.RandomForestRegressor(\n",
    "    #     n_estimators=200,\n",
    "    #     max_depth=10,\n",
    "    #     min_samples_leaf=5,\n",
    "    #     max_features='sqrt',\n",
    "    #     random_state=42\n",
    "    # )\n",
    "    regr_full = ensemble.RandomForestRegressor(random_state=42)\n",
    "    regr_full.fit(X_train_full, y_train)\n",
    "\n",
    "    # Select top N features\n",
    "    N = 5\n",
    "    importances = regr_full.feature_importances_\n",
    "    feature_importance_dict = dict(zip(predictors, importances))\n",
    "    selected_features = sorted(feature_importance_dict, key=feature_importance_dict.get, reverse=True)[:N]\n",
    "    print(f\"Selected features for {month}-{hour}: {selected_features}\")\n",
    "\n",
    "    # Re-train model on selected features (Here uncomment in the case of defined predictors or default predictors)\n",
    "    X_train = data_train[selected_features]\n",
    "    X_test = data_test[selected_features]\n",
    "    # regr = ensemble.RandomForestRegressor(\n",
    "    #     n_estimators=200,\n",
    "    #     max_depth=10,\n",
    "    #     min_samples_leaf=5,\n",
    "    #     max_features='sqrt',\n",
    "    #     random_state=42\n",
    "    # )\n",
    "    regr = ensemble.RandomForestRegressor(random_state=42)\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test\n",
    "    y_pred = regr.predict(X_test)\n",
    "    mae = round(mean_absolute_error(y_test, y_pred), 3)\n",
    "    rmse = round(math.sqrt(mean_squared_error(y_test, y_pred)), 3)\n",
    "    r2_test = round(r2_score(y_test, y_pred), 3)\n",
    "\n",
    "    # Predict on train\n",
    "    y_train_pred = regr.predict(X_train)\n",
    "    mae_train = round(mean_absolute_error(y_train, y_train_pred), 3)\n",
    "    rmse_train = round(math.sqrt(mean_squared_error(y_train, y_train_pred)), 3)\n",
    "    r2_train = round(r2_score(y_train, y_train_pred), 3)\n",
    "\n",
    "    # Feature importance (from final model)\n",
    "    feat_imp = dict(zip(selected_features, regr.feature_importances_))\n",
    "\n",
    "    print(f\"Done → TEST → MAE: {mae}, RMSE: {rmse}, R2: {r2_test}\")\n",
    "    print(f\"       TRAIN → MAE: {mae_train}, RMSE: {rmse_train}, R2: {r2_train}\")\n",
    "\n",
    "    # Predict full raster\n",
    "    raster_arrays = []\n",
    "    for pred in selected_features:\n",
    "        with rasterio.open(predictors_dict[pred]) as src:\n",
    "            array = src.read(1).astype(np.float32)\n",
    "            raster_arrays.append(array)\n",
    "            if pred == selected_features[0]:\n",
    "                meta = src.meta.copy()\n",
    "\n",
    "    stack = np.stack(raster_arrays, axis=0)\n",
    "    n_bands, height, width = stack.shape\n",
    "    flat_stack = stack.reshape(n_bands, -1).T\n",
    "\n",
    "    pred_full = regr.predict(flat_stack)\n",
    "    pred_raster = pred_full.reshape(height, width)\n",
    "\n",
    "    #Save prediction raster\n",
    "    meta.update({'count': 1, 'dtype': 'float32'})\n",
    "    #out_path = f'../Data/Predicted_maps/Automated/no_SM_LCZ/with_FS_defined_HP/pred_rf_{month}_{hour}.tif'\n",
    "    out_path = f'../Data/Predicted_maps/Automated/alt_corr/no_SM/with_FS_default_HP/pred_rf_{month}_{hour}.tif'\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with rasterio.open(out_path, 'w', **meta) as dst:\n",
    "        dst.write(pred_raster.astype(np.float32), 1)\n",
    "\n",
    "    print(f\"Prediction raster saved to {out_path}\")\n",
    "\n",
    "    result = {\n",
    "        'month': month,\n",
    "        'hour': hour,\n",
    "        'MAE_test': mae,\n",
    "        'RMSE_test': rmse,\n",
    "        'R2_test': r2_test,\n",
    "        'MAE_train': mae_train,\n",
    "        'RMSE_train': rmse_train,\n",
    "        'R2_train': r2_train,\n",
    "        **feat_imp\n",
    "    }\n",
    "\n",
    "    return result, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b61b61-e0b9-4bc4-b450-81f353fbc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = []\n",
    "selected_feats_all = []\n",
    "months = ['Feb', 'May', 'June', 'July', 'Oct']\n",
    "#months = ['May']\n",
    "hours = ['HP', 'WP', 'CP1', 'CP2', 'MUHI']\n",
    "#hours = ['WP']\n",
    "\n",
    "for m in months:\n",
    "    for h in hours:\n",
    "        result, selected_feats = run_rf_pipeline(m, h, selected_predictors, normalization)\n",
    "        results_all.append(result)\n",
    "        selected_feats_all.append({\n",
    "            \"month\": m,\n",
    "            \"hour\": h,\n",
    "            \"selected_features\": selected_feats\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a5fdc-38be-464d-9306-314167ee29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to DataFrame\n",
    "results_df = pd.DataFrame(results_all)\n",
    "results_df.to_csv('../Data/Predicted_maps/Automated/alt_corr/no_SM/with_FS_default_HP/RF_results_withFS_defaultHP.csv', index=False)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509f248-a648-4963-993e-29fc3bcccabb",
   "metadata": {},
   "source": [
    "# With CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e432ee1-5867-40fc-a145-77ccd804a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_pipeline(month, hour, predictors, normalization):\n",
    "\n",
    "    print(f\"Running pipeline for {month} - {hour}...\")\n",
    "\n",
    "    # Load temperature data. Here uncomment when needed\n",
    "    #data = f'../Data/CML/HW_extracted/HW_{month}_2022/CML-ARPA_HW_{month}_2022_{hour}.csv'\n",
    "    data = f'../Data/CML/HW_extracted/alt_corr1/CML-ARPA_HW_{month}_2022_{hour}.csv'\n",
    "    #data = f'../Data/CML/HW_extracted/meteotracker/22052022.csv'\n",
    "    data_df = pd.read_csv(data)\n",
    "\n",
    "    geometry = [Point(xy) for xy in zip(data_df['long'], data_df['lat'])]\n",
    "    data_gdf = gpd.GeoDataFrame(data_df, geometry=geometry, crs='EPSG:4326')\n",
    "    data_gdf = data_gdf.to_crs(epsg=32632)\n",
    "\n",
    "    # Merge LCZ and train/test labels\n",
    "    data_class_df = pd.read_csv('../Data/LCZ/ARPA_CML_stations_LCZ.csv', delimiter=',')\n",
    "    #data_class_df = data_class_df[data_class_df['network']=='ARPA'] # Uncomment here to select only ARPA or CML stations\n",
    "    data_class_df = data_class_df[['station', 'dominant_class', 'train/test', 'urban/natural']]\n",
    "    data_class_df.rename(columns={'dominant_class': 'LCZ'}, inplace=True)\n",
    "\n",
    "    merged_df = pd.merge(data_gdf, data_class_df, on='station', how='inner')\n",
    "    data_train = merged_df.loc[merged_df['train/test'] == 'train'].copy()\n",
    "    data_test = merged_df.loc[merged_df['train/test'] == 'test'].copy()\n",
    "\n",
    "# ------- STRATIFIED SAMPLING -------\n",
    "    # Uncomment when needed\n",
    "    #STRATIFIED SPLIT by station and 'urban/natural'\n",
    "    # station_meta = merged_df[['station', 'urban/natural']].drop_duplicates()\n",
    "\n",
    "    # train_stations, test_stations = train_test_split(\n",
    "    #     station_meta,\n",
    "    #     test_size=0.3,  # adjust test size as needed\n",
    "    #     stratify=station_meta['urban/natural'],\n",
    "    #     random_state=42\n",
    "    # )\n",
    "    \n",
    "    # data_train = merged_df[merged_df['station'].isin(train_stations['station'])].copy()\n",
    "    # data_test = merged_df[merged_df['station'].isin(test_stations['station'])].copy()\n",
    "\n",
    "# -------------------\n",
    "\n",
    "    # Select predictor paths\n",
    "    # predictors_dict = {\n",
    "    #     'NDVI': f'../Data/NDVI/NDVI_2022_{month}_mean.tif',\n",
    "    #     'NDLI': f'../Data/NDLI/NDLI_2022_{month}_mean.tif',\n",
    "    #     'LCZ': f'../Data/LCZ/LCZ_{month}_20m_majority.tif',\n",
    "    #     'IMD': '../Data/IMD_Copernicus_2018/IMD_Copernicus_2018_20m_mean.tif',\n",
    "    #     'SWIR1': f'../Data/SWIR/SWIR1_2022_{month}_mean.tif',\n",
    "    #     'SWIR2': f'../Data/SWIR/SWIR2_2022_{month}_mean.tif',\n",
    "    #     'SVF': '../Data/SVF/SVF_Final_20m_mean.tif',\n",
    "    #     'DTM': '../Data/Elevation/Elevation_20m_mean.tif',\n",
    "    #     'SM': f'../Data/Soil_Moisture/Soil_Moisture_2022_{month}_mean.tif',\n",
    "    #     'CH': '../Data/Canopy_Heights_ETH/Canopy_Heights_ETH_20m_norm_mean.tif'\n",
    "    # }\n",
    "\n",
    "    # Predictors with a buffer of 150m around\n",
    "    predictors_dict = {\n",
    "        'NDVI': f'../Data/NDVI/NDVI_2022_{month}_mean150.tif',\n",
    "        'NDLI': f'../Data/NDLI/NDLI_2022_{month}_mean150.tif',\n",
    "        'LCZ': f'../Data/LCZ/LCZ_{month}_20m_majority150.tif',\n",
    "        'IMD': '../Data/IMD_Copernicus_2018/IMD_Copernicus_2018_20m_mean150.tif',\n",
    "        'SWIR1': f'../Data/SWIR/SWIR1_2022_{month}_mean150.tif',\n",
    "        'SWIR2': f'../Data/SWIR/SWIR2_2022_{month}_mean150.tif',\n",
    "        'SVF': '../Data/SVF/SVF_Final_20m_mean150.tif',\n",
    "        'DTM': '../Data/Elevation/Elevation_20m_mean150.tif',\n",
    "        'SM': f'../Data/Soil_Moisture/Soil_Moisture_2022_{month}_mean150.tif',\n",
    "        'CH': '../Data/Canopy_Heights_ETH/Canopy_Heights_ETH_20m_mean150.tif'\n",
    "    }\n",
    "\n",
    "    if normalization == 'YES':\n",
    "        predictors_dict.update({\n",
    "            'LCZ': f'../Data/LCZ/LCZ_{month}_20m_norm_majority.tif',\n",
    "            'IMD': '../Data/IMD_Copernicus_2018/IMD_Copernicus_2018_20m_norm_mean.tif',\n",
    "            'SWIR1': f'../Data/SWIR/SWIR1_2022_{month}_norm_mean.tif',\n",
    "            'SWIR2': f'../Data/SWIR/SWIR2_2022_{month}_norm_mean.tif',\n",
    "            'DTM': '../Data/Elevation/Elevation_20m_norm_mean.tif',\n",
    "        })\n",
    "    \n",
    "    predictors_dict = {k: v for k, v in predictors_dict.items() if k in predictors}\n",
    "    selected_features = list(predictors_dict.keys())\n",
    "\n",
    "    # Sample predictors\n",
    "    for pred in predictors_dict:\n",
    "        raster = predictors_dict[pred]\n",
    "        data_train[pred] = point_query(data_train.geometry, raster, nodata=-999)\n",
    "        data_test[pred] = point_query(data_test.geometry, raster, nodata=-999)\n",
    "\n",
    "    # Drop rows with any NaNs in predictors\n",
    "    data_train = data_train.dropna(subset=predictors)\n",
    "    data_test = data_test.dropna(subset=predictors)\n",
    "    \n",
    "    # Train/Test split\n",
    "    X_train = data_train[predictors]\n",
    "    y_train = data_train['avg_temp']\n",
    "    X_test = data_test[predictors]\n",
    "    y_test = data_test['avg_temp']\n",
    "\n",
    "    # --- Hyperparameter Tuning ---\n",
    "    param_dist = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'max_features': ['sqrt', 0.8, 1.0],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    print(f\"Best hyperparameters for {month}-{hour}: {best_params}\")\n",
    "\n",
    "    # Train final model using best hyperparameters\n",
    "    regr = RandomForestRegressor(**best_params, random_state=42)\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # --- Prediction and Evaluation ---\n",
    "    y_pred = regr.predict(X_test)\n",
    "    mae = round(mean_absolute_error(y_test, y_pred), 3)\n",
    "    rmse = round(math.sqrt(mean_squared_error(y_test, y_pred)), 3)\n",
    "    r2_test = round(r2_score(y_test, y_pred), 3)\n",
    "\n",
    "    y_train_pred = regr.predict(X_train)\n",
    "    mae_train = round(mean_absolute_error(y_train, y_train_pred), 3)\n",
    "    rmse_train = round(math.sqrt(mean_squared_error(y_train, y_train_pred)), 3)\n",
    "    r2_train = round(r2_score(y_train, y_train_pred), 3)\n",
    "\n",
    "    # Feature importance (from final model)\n",
    "    feat_imp = dict(zip(selected_features, regr.feature_importances_))\n",
    "\n",
    "    print(f\"Done → TEST → MAE: {mae}, RMSE: {rmse}, R2: {r2_test}\")\n",
    "    print(f\"       TRAIN → MAE: {mae_train}, RMSE: {rmse_train}, R2: {r2_train}\")\n",
    "\n",
    "    # Predict full raster\n",
    "    raster_arrays = []\n",
    "    for pred in selected_features:\n",
    "        with rasterio.open(predictors_dict[pred]) as src:\n",
    "            array = src.read(1).astype(np.float32)\n",
    "            raster_arrays.append(array)\n",
    "            if pred == selected_features[0]:\n",
    "                meta = src.meta.copy()\n",
    "\n",
    "    stack = np.stack(raster_arrays, axis=0)\n",
    "    n_bands, height, width = stack.shape\n",
    "    flat_stack = stack.reshape(n_bands, -1).T\n",
    "\n",
    "    pred_full = regr.predict(flat_stack)\n",
    "    pred_raster = pred_full.reshape(height, width)\n",
    "\n",
    "    #Save prediction raster\n",
    "    meta.update({'count': 1, 'dtype': 'float32'})\n",
    "    #out_path = f'../Data/Predicted_maps/Automated/no_SM_LCZ/with_FS_defined_HP/pred_rf_{month}_{hour}.tif'\n",
    "    out_path = f'../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150/pred_rf_{month}_{hour}.tif'\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with rasterio.open(out_path, 'w', **meta) as dst:\n",
    "        dst.write(pred_raster.astype(np.float32), 1)\n",
    "\n",
    "    print(f\"Prediction raster saved to {out_path}\")\n",
    "\n",
    "    result = {\n",
    "        'month': month,\n",
    "        'hour': hour,\n",
    "        'MAE_test': mae,\n",
    "        'RMSE_test': rmse,\n",
    "        'R2_test': r2_test,\n",
    "        'MAE_train': mae_train,\n",
    "        'RMSE_train': rmse_train,\n",
    "        'R2_train': r2_train,\n",
    "        **dict(zip(predictors, regr.feature_importances_))\n",
    "    }\n",
    "\n",
    "    return result, selected_features, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ba89a4-ebca-4939-b8a5-a6ee693443ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Running for Feb - HP\n",
      "Running pipeline for Feb - HP...\n",
      "Best hyperparameters for Feb-HP: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.55, RMSE: 0.643, R2: 0.137\n",
      "       TRAIN → MAE: 0.239, RMSE: 0.306, R2: 0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Feb_HP.tif\n",
      "\n",
      ">>> Running for Feb - WP\n",
      "Running pipeline for Feb - WP...\n",
      "Best hyperparameters for Feb-WP: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "Done → TEST → MAE: 0.546, RMSE: 0.738, R2: -0.241\n",
      "       TRAIN → MAE: 0.315, RMSE: 0.44, R2: 0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Feb_WP.tif\n",
      "\n",
      ">>> Running for Feb - CP1\n",
      "Running pipeline for Feb - CP1...\n",
      "Best hyperparameters for Feb-CP1: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "Done → TEST → MAE: 0.622, RMSE: 0.824, R2: -0.492\n",
      "       TRAIN → MAE: 0.316, RMSE: 0.383, R2: 0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Feb_CP1.tif\n",
      "\n",
      ">>> Running for Feb - CP2\n",
      "Running pipeline for Feb - CP2...\n",
      "Best hyperparameters for Feb-CP2: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 1.323, RMSE: 1.606, R2: 0.187\n",
      "       TRAIN → MAE: 0.655, RMSE: 0.82, R2: 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Feb_CP2.tif\n",
      "\n",
      ">>> Running for Feb - MUHI\n",
      "Running pipeline for Feb - MUHI...\n",
      "Best hyperparameters for Feb-MUHI: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 1.048, RMSE: 1.309, R2: 0.135\n",
      "       TRAIN → MAE: 0.523, RMSE: 0.688, R2: 0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Feb_MUHI.tif\n",
      "\n",
      ">>> Running for May - HP\n",
      "Running pipeline for May - HP...\n",
      "Best hyperparameters for May-HP: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.532, RMSE: 0.641, R2: -0.068\n",
      "       TRAIN → MAE: 0.376, RMSE: 0.487, R2: 0.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_May_HP.tif\n",
      "\n",
      ">>> Running for May - WP\n",
      "Running pipeline for May - WP...\n",
      "Best hyperparameters for May-WP: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.891, RMSE: 1.07, R2: -0.225\n",
      "       TRAIN → MAE: 0.32, RMSE: 0.406, R2: 0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_May_WP.tif\n",
      "\n",
      ">>> Running for May - CP1\n",
      "Running pipeline for May - CP1...\n",
      "Best hyperparameters for May-CP1: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.788, RMSE: 0.99, R2: -0.037\n",
      "       TRAIN → MAE: 0.417, RMSE: 0.526, R2: 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_May_CP1.tif\n",
      "\n",
      ">>> Running for May - CP2\n",
      "Running pipeline for May - CP2...\n",
      "Best hyperparameters for May-CP2: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 1.169, RMSE: 1.382, R2: 0.058\n",
      "       TRAIN → MAE: 0.543, RMSE: 0.698, R2: 0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_May_CP2.tif\n",
      "\n",
      ">>> Running for May - MUHI\n",
      "Running pipeline for May - MUHI...\n",
      "Best hyperparameters for May-MUHI: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "Done → TEST → MAE: 1.045, RMSE: 1.291, R2: 0.089\n",
      "       TRAIN → MAE: 0.508, RMSE: 0.646, R2: 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_May_MUHI.tif\n",
      "\n",
      ">>> Running for June - HP\n",
      "Running pipeline for June - HP...\n",
      "Best hyperparameters for June-HP: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 0.8, 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.443, RMSE: 0.58, R2: 0.165\n",
      "       TRAIN → MAE: 0.392, RMSE: 0.545, R2: 0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_June_HP.tif\n",
      "\n",
      ">>> Running for June - WP\n",
      "Running pipeline for June - WP...\n",
      "Best hyperparameters for June-WP: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.633, RMSE: 0.82, R2: -0.188\n",
      "       TRAIN → MAE: 0.285, RMSE: 0.397, R2: 0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_June_WP.tif\n",
      "\n",
      ">>> Running for June - CP1\n",
      "Running pipeline for June - CP1...\n",
      "Best hyperparameters for June-CP1: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.782, RMSE: 0.972, R2: -0.103\n",
      "       TRAIN → MAE: 0.378, RMSE: 0.498, R2: 0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_June_CP1.tif\n",
      "\n",
      ">>> Running for June - CP2\n",
      "Running pipeline for June - CP2...\n",
      "Best hyperparameters for June-CP2: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.8, 'max_depth': 10}\n",
      "Done → TEST → MAE: 1.162, RMSE: 1.423, R2: 0.133\n",
      "       TRAIN → MAE: 0.411, RMSE: 0.523, R2: 0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_June_CP2.tif\n",
      "\n",
      ">>> Running for June - MUHI\n",
      "Running pipeline for June - MUHI...\n",
      "Best hyperparameters for June-MUHI: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 1.149, RMSE: 1.396, R2: 0.217\n",
      "       TRAIN → MAE: 0.531, RMSE: 0.673, R2: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_June_MUHI.tif\n",
      "\n",
      ">>> Running for July - HP\n",
      "Running pipeline for July - HP...\n",
      "Best hyperparameters for July-HP: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.453, RMSE: 0.591, R2: 0.06\n",
      "       TRAIN → MAE: 0.476, RMSE: 0.618, R2: 0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_July_HP.tif\n",
      "\n",
      ">>> Running for July - WP\n",
      "Running pipeline for July - WP...\n",
      "Best hyperparameters for July-WP: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.721, RMSE: 0.889, R2: -0.273\n",
      "       TRAIN → MAE: 0.305, RMSE: 0.429, R2: 0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_July_WP.tif\n",
      "\n",
      ">>> Running for July - CP1\n",
      "Running pipeline for July - CP1...\n",
      "Best hyperparameters for July-CP1: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 20}\n",
      "Done → TEST → MAE: 0.774, RMSE: 1.019, R2: -0.197\n",
      "       TRAIN → MAE: 0.295, RMSE: 0.421, R2: 0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_July_CP1.tif\n",
      "\n",
      ">>> Running for July - CP2\n",
      "Running pipeline for July - CP2...\n",
      "Best hyperparameters for July-CP2: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 30}\n",
      "Done → TEST → MAE: 1.153, RMSE: 1.504, R2: -0.039\n",
      "       TRAIN → MAE: 0.394, RMSE: 0.535, R2: 0.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_July_CP2.tif\n",
      "\n",
      ">>> Running for July - MUHI\n",
      "Running pipeline for July - MUHI...\n",
      "Best hyperparameters for July-MUHI: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 1.042, RMSE: 1.293, R2: 0.25\n",
      "       TRAIN → MAE: 0.471, RMSE: 0.633, R2: 0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_July_MUHI.tif\n",
      "\n",
      ">>> Running for Oct - HP\n",
      "Running pipeline for Oct - HP...\n",
      "Best hyperparameters for Oct-HP: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.514, RMSE: 0.632, R2: -0.054\n",
      "       TRAIN → MAE: 0.407, RMSE: 0.595, R2: 0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Oct_HP.tif\n",
      "\n",
      ">>> Running for Oct - WP\n",
      "Running pipeline for Oct - WP...\n",
      "Best hyperparameters for Oct-WP: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 0.8, 'max_depth': 20}\n",
      "Done → TEST → MAE: 0.549, RMSE: 0.704, R2: 0.243\n",
      "       TRAIN → MAE: 0.396, RMSE: 0.502, R2: 0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Oct_WP.tif\n",
      "\n",
      ">>> Running for Oct - CP1\n",
      "Running pipeline for Oct - CP1...\n",
      "Best hyperparameters for Oct-CP1: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "Done → TEST → MAE: 0.775, RMSE: 1.032, R2: 0.031\n",
      "       TRAIN → MAE: 0.464, RMSE: 0.627, R2: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Oct_CP1.tif\n",
      "\n",
      ">>> Running for Oct - CP2\n",
      "Running pipeline for Oct - CP2...\n",
      "Best hyperparameters for Oct-CP2: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 1.0, 'max_depth': 20}\n",
      "Done → TEST → MAE: 0.972, RMSE: 1.212, R2: 0.179\n",
      "       TRAIN → MAE: 0.415, RMSE: 0.53, R2: 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Oct_CP2.tif\n",
      "\n",
      ">>> Running for Oct - MUHI\n",
      "Running pipeline for Oct - MUHI...\n",
      "Best hyperparameters for Oct-MUHI: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 30}\n",
      "Done → TEST → MAE: 0.8, RMSE: 0.936, R2: 0.196\n",
      "       TRAIN → MAE: 0.276, RMSE: 0.338, R2: 0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction raster saved to ../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150_CV-100/pred_rf_Oct_MUHI.tif\n"
     ]
    }
   ],
   "source": [
    "results_all = []\n",
    "selected_feats_all = []\n",
    "best_params_all = []\n",
    "\n",
    "months = ['Feb', 'May', 'June', 'July', 'Oct']\n",
    "hours = ['HP', 'WP', 'CP1', 'CP2', 'MUHI']\n",
    "\n",
    "for m in months:\n",
    "    for h in hours:\n",
    "        print(f\"\\n>>> Running for {m} - {h}\")\n",
    "        # Assuming selected_predictors and normalization are defined outside\n",
    "        result, selected_features, best_params = run_rf_pipeline(m, h, selected_predictors, normalization)\n",
    "        \n",
    "        results_all.append(result)\n",
    "        selected_feats_all.append({\n",
    "            \"month\": m,\n",
    "            \"hour\": h,\n",
    "            \"selected_features\": selected_features\n",
    "        })\n",
    "        best_params_all.append({\n",
    "            \"month\": m,\n",
    "            \"hour\": h,\n",
    "            **best_params\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0091e8c5-f40c-435b-b443-d6f73a8d1b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All results saved.\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results_all)\n",
    "results_df.to_csv('../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150/RF_results.csv', index=False)\n",
    "\n",
    "selected_feats_df = pd.DataFrame(selected_feats_all)\n",
    "selected_feats_df.to_csv('../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150/RF_selected_feats.csv', index=False)\n",
    "\n",
    "best_params_df = pd.DataFrame(best_params_all)\n",
    "best_params_df.to_csv('../Data/Predicted_maps/Automated/alt_corr1/with_CV/no_SM_no_DTM/no_FS_best_HP_buffer_150/RF_best_params.csv', index=False)\n",
    "\n",
    "print(\"All results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f370ea9-b150-495c-ba08-5f95d881b732",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# With Recursive Feature Elimination (RFE) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550f04b-a63c-461c-8ba3-745ce5bb1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_pipeline(month, hour, predictors, normalization):\n",
    "\n",
    "    print(f\"Running pipeline for {month} - {hour}...\")\n",
    "\n",
    "    # Load temperature data. Here uncomment when needed\n",
    "    #data = f'../Data/CML/HW_extracted/HW_{month}_2022/CML-ARPA_HW_{month}_2022_{hour}.csv'\n",
    "    data = f'../Data/CML/HW_extracted/alt_corr/CML-ARPA_HW_{month}_2022_{hour}.csv'\n",
    "    #data = f'../Data/CML/HW_extracted/meteotracker/22052022.csv'\n",
    "    data_df = pd.read_csv(data)\n",
    "\n",
    "    geometry = [Point(xy) for xy in zip(data_df['long'], data_df['lat'])]\n",
    "    data_gdf = gpd.GeoDataFrame(data_df, geometry=geometry, crs='EPSG:4326')\n",
    "    data_gdf = data_gdf.to_crs(epsg=32632)\n",
    "\n",
    "    # Merge LCZ and train/test labels\n",
    "    data_class_df = pd.read_csv('../Data/LCZ/ARPA_CML_stations_LCZ.csv', delimiter=',')\n",
    "    #data_class_df = data_class_df[data_class_df['network']=='ARPA'] # Uncomment here to select only ARPA or CML stations\n",
    "    data_class_df = data_class_df[['station', 'dominant_class', 'train/test', 'urban/natural']]\n",
    "    data_class_df.rename(columns={'dominant_class': 'LCZ'}, inplace=True)\n",
    "\n",
    "    merged_df = pd.merge(data_gdf, data_class_df, on='station', how='inner')\n",
    "    data_train = merged_df.loc[merged_df['train/test'] == 'train'].copy()\n",
    "    data_test = merged_df.loc[merged_df['train/test'] == 'test'].copy()\n",
    "\n",
    "    # Select predictor paths\n",
    "    predictors_dict = {\n",
    "        'NDVI': f'../Data/NDVI/NDVI_2022_{month}_mean.tif',\n",
    "        'NDLI': f'../Data/NDLI/NDLI_2022_{month}_mean.tif',\n",
    "        'LCZ': f'../Data/LCZ/LCZ_{month}_20m_majority.tif',\n",
    "        'IMD': '../Data/IMD_Copernicus_2018/IMD_Copernicus_2018_20m_mean.tif',\n",
    "        'SWIR1': f'../Data/SWIR/SWIR1_2022_{month}_mean.tif',\n",
    "        'SWIR2': f'../Data/SWIR/SWIR2_2022_{month}_mean.tif',\n",
    "        'SVF': '../Data/SVF/SVF_Final_20m_mean.tif',\n",
    "        'DTM': '../Data/Elevation/Elevation_20m_mean.tif',\n",
    "        'SM': f'../Data/Soil_Moisture/Soil_Moisture_2022_{month}_mean.tif',\n",
    "        'CH': '../Data/Canopy_Heights_ETH/Canopy_Heights_ETH_20m_norm_mean.tif'\n",
    "    }\n",
    "\n",
    "    if normalization == 'YES':\n",
    "        predictors_dict.update({\n",
    "            'LCZ': f'../Data/LCZ/LCZ_{month}_20m_norm_majority.tif',\n",
    "            'IMD': '../Data/IMD_Copernicus_2018/IMD_Copernicus_2018_20m_norm_mean.tif',\n",
    "            'SWIR1': f'../Data/SWIR/SWIR1_2022_{month}_norm_mean.tif',\n",
    "            'SWIR2': f'../Data/SWIR/SWIR2_2022_{month}_norm_mean.tif',\n",
    "            'DTM': '../Data/Elevation/Elevation_20m_norm_mean.tif',\n",
    "        })\n",
    "    \n",
    "    predictors_dict = {k: v for k, v in predictors_dict.items() if k in predictors}\n",
    "    selected_features = list(predictors_dict.keys())\n",
    "\n",
    "    # Sample predictors\n",
    "    for pred in predictors_dict:\n",
    "        raster = predictors_dict[pred]\n",
    "        data_train[pred] = point_query(data_train.geometry, raster, nodata=-999)\n",
    "        data_test[pred] = point_query(data_test.geometry, raster, nodata=-999)\n",
    "\n",
    "    # Drop rows with any NaNs in predictors\n",
    "    data_train = data_train.dropna(subset=predictors)\n",
    "    data_test = data_test.dropna(subset=predictors)\n",
    "\n",
    "    initial_features = selected_features\n",
    "    X_train_raw = data_train[initial_features]\n",
    "    y_train = data_train['avg_temp']\n",
    "\n",
    "# ------- RFE feature selection -------\n",
    "\n",
    "    base_rf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    rfe = RFE(estimator=base_rf, n_features_to_select=5)\n",
    "    rfe.fit(X_train_raw, y_train)\n",
    "    \n",
    "    # Selected features\n",
    "    selected_features = list(np.array(initial_features)[rfe.support_])\n",
    "    print(f\"Selected features by RFE for {month}-{hour}: {selected_features}\")\n",
    "\n",
    "    # Feature ranking\n",
    "    feature_ranking = pd.DataFrame({\n",
    "        'feature': initial_features,\n",
    "        'rank': rfe.ranking_,\n",
    "        'selected': rfe.support_\n",
    "    })\n",
    "        \n",
    "    # Train/Test split\n",
    "    X_train = data_train[selected_features]\n",
    "    y_train = data_train['avg_temp']\n",
    "    X_test = data_test[selected_features]\n",
    "    y_test = data_test['avg_temp']\n",
    "\n",
    "# -------\n",
    "\n",
    "    # --- Hyperparameter Tuning ---\n",
    "    param_dist = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'max_features': ['sqrt', 0.8, 1.0],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    print(f\"Best hyperparameters for {month}-{hour}: {best_params}\")\n",
    "\n",
    "    # Train final model using best hyperparameters\n",
    "    regr = RandomForestRegressor(**best_params, random_state=42)\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # --- Prediction and Evaluation ---\n",
    "    y_pred = regr.predict(X_test)\n",
    "    mae = round(mean_absolute_error(y_test, y_pred), 3)\n",
    "    rmse = round(math.sqrt(mean_squared_error(y_test, y_pred)), 3)\n",
    "    r2_test = round(r2_score(y_test, y_pred), 3)\n",
    "\n",
    "    y_train_pred = regr.predict(X_train)\n",
    "    mae_train = round(mean_absolute_error(y_train, y_train_pred), 3)\n",
    "    rmse_train = round(math.sqrt(mean_squared_error(y_train, y_train_pred)), 3)\n",
    "    r2_train = round(r2_score(y_train, y_train_pred), 3)\n",
    "\n",
    "    # Feature importance (from final model)\n",
    "    feat_imp = dict(zip(selected_features, regr.feature_importances_))\n",
    "\n",
    "    print(f\"Done → TEST → MAE: {mae}, RMSE: {rmse}, R2: {r2_test}\")\n",
    "    print(f\"       TRAIN → MAE: {mae_train}, RMSE: {rmse_train}, R2: {r2_train}\")\n",
    "\n",
    "    # Predict full raster\n",
    "    raster_arrays = []\n",
    "    for pred in selected_features:\n",
    "        with rasterio.open(predictors_dict[pred]) as src:\n",
    "            array = src.read(1).astype(np.float32)\n",
    "            raster_arrays.append(array)\n",
    "            if pred == selected_features[0]:\n",
    "                meta = src.meta.copy()\n",
    "\n",
    "    stack = np.stack(raster_arrays, axis=0)\n",
    "    n_bands, height, width = stack.shape\n",
    "    flat_stack = stack.reshape(n_bands, -1).T\n",
    "\n",
    "    pred_full = regr.predict(flat_stack)\n",
    "    pred_raster = pred_full.reshape(height, width)\n",
    "\n",
    "    #Save prediction raster\n",
    "    meta.update({'count': 1, 'dtype': 'float32'})\n",
    "    #out_path = f'../Data/Predicted_maps/Automated/no_SM_LCZ/with_FS_defined_HP/pred_rf_{month}_{hour}.tif'\n",
    "    out_path = f'../Data/Predicted_maps/Automated/alt_corr/no_SM/RFE_FS_best_HP/pred_rf_{month}_{hour}.tif'\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with rasterio.open(out_path, 'w', **meta) as dst:\n",
    "        dst.write(pred_raster.astype(np.float32), 1)\n",
    "\n",
    "    print(f\"Prediction raster saved to {out_path}\")\n",
    "\n",
    "    result = {\n",
    "        'month': month,\n",
    "        'hour': hour,\n",
    "        'MAE_test': mae,\n",
    "        'RMSE_test': rmse,\n",
    "        'R2_test': r2_test,\n",
    "        'MAE_train': mae_train,\n",
    "        'RMSE_train': rmse_train,\n",
    "        'R2_train': r2_train,\n",
    "        **dict(zip(selected_features, regr.feature_importances_))\n",
    "    }\n",
    "\n",
    "    return result, selected_features, best_params, feature_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e8aae-09b6-4ba3-8f08-ba721f0f15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = []\n",
    "selected_feats_all = []\n",
    "best_params_all = []\n",
    "\n",
    "months = ['Feb', 'May', 'June', 'July', 'Oct']\n",
    "hours = ['HP', 'WP', 'CP1', 'CP2', 'MUHI']\n",
    "\n",
    "for m in months:\n",
    "    for h in hours:\n",
    "        print(f\"\\n>>> Running for {m} - {h}\")\n",
    "        # Assuming selected_predictors and normalization are defined outside\n",
    "        result, selected_features, best_params, feature_ranking = run_rf_pipeline(m, h, selected_predictors, normalization)\n",
    "        \n",
    "        results_all.append(result)\n",
    "        selected_feats_all.append({\n",
    "            \"month\": m,\n",
    "            \"hour\": h,\n",
    "            \"selected_features\": selected_features\n",
    "        })\n",
    "        best_params_all.append({\n",
    "            \"month\": m,\n",
    "            \"hour\": h,\n",
    "            **best_params\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba25b75-e3ac-4510-9ba1-f8ed49aca2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_all)\n",
    "results_df.to_csv('../Data/Predicted_maps/Automated/alt_corr/no_SM/RFE_FS_best_HP/RF_results.csv', index=False)\n",
    "\n",
    "selected_feats_df = pd.DataFrame(selected_feats_all)\n",
    "selected_feats_df.to_csv('../Data/Predicted_maps/Automated/alt_corr/no_SM/RFE_FS_best_HP/RF_selected_feats.csv', index=False)\n",
    "\n",
    "best_params_df = pd.DataFrame(best_params_all)\n",
    "best_params_df.to_csv('../Data/Predicted_maps/Automated/alt_corr/no_SM/RFE_FS_best_HP/RF_best_params.csv', index=False)\n",
    "\n",
    "print(\"All results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec4f64-a48e-4e75-9075-1f3125a740fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
